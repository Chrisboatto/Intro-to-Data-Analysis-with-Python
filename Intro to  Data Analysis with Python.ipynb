{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Acquisition\n",
    "\n",
    "#There are various formats for a dataset, .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.\n",
    "#In this section, you will learn how to load a dataset into our Jupyter Notebook\n",
    "#In our case, the Automobile Dataset is an online source, and it is in CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n",
    "\n",
    "#data source:  href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "    #data type: csv\n",
    "\n",
    "#The Pandas Library is a useful tool that enables us to read various datasets into a data frame; our Jupyter notebook platforms have a built-in Pandas Library so that all we need to do is import Pandas without installing.\n",
    "\n",
    "# import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "\n",
    "#We use pandas.read_csv() function to read the csv file. \n",
    "#In the bracket, we put the file path along with a quotation mark, \n",
    "#so that pandas will read the file into a data frame from that address. \n",
    "#The file path can be either an URL or your local file address.\n",
    "#Because the data does not include headers, we can add an argument headers = None\n",
    "#inside the  read_csv() method, so that pandas will not automatically set the first row as a header.\n",
    "#You can also assign the dataset to any variable you create.\n",
    "\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "other_path = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\n",
    "df = pd.read_csv(other_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After reading the dataset, we can use the dataframe.head(n) method to check the top n rows of the dataframe;\n",
    "#where n is an integer. Contrary to dataframe.head(n), \n",
    "#dataframe.tail(n) will show you the bottom n rows of the dataframe.\n",
    "\n",
    "# show the first 5 rows using dataframe.head() method\n",
    "print(\"The first 5 rows of the dataframe\") \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question #1:\n",
    "#check the bottom 10 rows of data frame \"df\".\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Headers\n",
    "\n",
    "#Take a look at our dataset; pandas automatically set the header by an integer from 0.\n",
    "\n",
    "#To better describe our data we can introduce a header, this information is available at:\n",
    "#href=\"https://archive.ics.uci.edu/ml/datasets/Automobile\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "\n",
    "#Thus, we have to add headers manually.\n",
    "\n",
    "#Firstly, we create a list \"headers\" that include all column names in order.\n",
    "#Then, we use dataframe.columns = headers to replace the headers by the list we created.\n",
    "\n",
    "# create headers list\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "print(\"headers\\n\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We replace headers and recheck our data frame\n",
    "\n",
    "df.columns = headers\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can drop missing values along the column \"price\" as follows  \n",
    "\n",
    "df.dropna(subset=['price'], axis=0)\n",
    "\n",
    "#Now, we have successfully read the raw dataset and add the correct headers into the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question #2:\n",
    "\n",
    "#Find the name of the columns of the dataframe\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Dataset\n",
    "\n",
    "#Correspondingly, Pandas enables us to save the dataset to csv  by using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n",
    "\n",
    "#For example, if you would save the dataframe df as automobile.csv to your local machine, you may use the syntax below:\n",
    "\n",
    "df.to_csv(\"automobile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Insights of a Dataset\n",
    "\n",
    "#After reading data into Pandas dataframe, it is time for us to explore the dataset.\n",
    "#There are several ways to obtain essential insights of the data to help us better understand our dataset.\n",
    "\n",
    "#Data Types\n",
    "\n",
    "#Data has a variety of types.\n",
    "#The main types stored in Pandas dataframes are <b>object, float, int, bool\n",
    "#and datetime64. In order to better learn about each attribute, \n",
    "#it is always good for us to know the data type of each column. In Pandas:\n",
    "\n",
    "df.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a Series with the data type of each column.\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As a result, as shown above, it is clear to see that the data type of \"symboling\" and \"curb-weight\" \n",
    "#are int64, \"normalized-losses\" is object, and \"wheel-base\" is float64, etc.\n",
    "\n",
    "#These data types can be changed; we will learn how to accomplish this in a later module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe\n",
    "\n",
    "#If we would like to get a statistical summary of each column, such as count,\n",
    "#column mean value, column standard deviation, etc. We use the describe method\n",
    "\n",
    "#This method will provide various summary statistics, excluding NaN (Not a Number) values.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows the statistical summary of all numeric-typed (int, float) columns.\n",
    "#For example, the attribute \"symboling\" has 205 counts, the mean value of this column is 0.83,\n",
    "#the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1,\n",
    "#75th percentile is 2, and the maximum value is 3.\n",
    "\n",
    "#However, what if we would also like to check all the columns including those that are of type object.\n",
    "\n",
    "#You can add an argument include = \"all\" inside the bracket. Let's try it again.\n",
    "\n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, it provides the statistical summary of all the columns, including object-typed attributes.\n",
    "#We can now see how many unique values, which is the top value and the frequency of top value in the object-typed columns.\n",
    "#Some values in the table above show as \"NaN\", this is because those numbers are not available regarding a particular column type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question #3:\n",
    "\n",
    "#You can select the columns of a data frame by indicating the name of  each column, for example, you can select the three columns as follows:\n",
    "\n",
    "#dataframe[[' column 1 ',column 2', 'column 3']]\n",
    "\n",
    "#Where \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n",
    "\n",
    "#dataframe[[' column 1 ',column 2', 'column 3'] ].describe()\n",
    "\n",
    "#Apply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "df[['length', 'compression-ratio']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info\n",
    "#Another method you can use to check your dataset is:\n",
    "\n",
    "df.info\n",
    "\n",
    "#It provides a concise summary of your DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
